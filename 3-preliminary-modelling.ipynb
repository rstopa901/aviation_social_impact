{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3a6448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ff1f6",
   "metadata": {},
   "source": [
    "# Preliminary Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668c1a0",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ef6eb",
   "metadata": {},
   "source": [
    "With our data fully cleaned, examined, and processed, we can move on to training an interpretable classifier model to determine the factors that affect accident severity.\n",
    "\n",
    "We will begin by bringing in our completed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f38022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing cleaned and vectorized datasets\n",
    "X_train_tfidf = pd.read_pickle('./data/train')\n",
    "X_test_tfidf = pd.read_pickle('./data/test')\n",
    "y_train = pd.read_pickle('./data/train_severity')\n",
    "y_test = pd.read_pickle('./data/test_severity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4aaa26",
   "metadata": {},
   "source": [
    "Since our processed data is both extremely large and extremely sparse, we can convert it to a sparse format in order to improve model training speed by representing our data in a more compact way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4699ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting feature datasets into sparse matrices for time efficiency\n",
    "X_train_sparse = X_train_tfidf.astype(pd.SparseDtype(\"float64\",0)).sparse.to_coo()\n",
    "X_test_sparse = X_test_tfidf.astype(pd.SparseDtype(\"float64\",0)).sparse.to_coo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee367b",
   "metadata": {},
   "source": [
    "Similarly, we can convert our target data, accident severity, into a binary numeric format to increase the interpretability of our model's results. Since we are primarly concerned with extremely severe accidents, we can numerically encode our severity as either 'fatal' or 'non-fatal', as done in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb75a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting multi-class severity target data into a binary of fatal vs non-fatal\n",
    "y_train = (y_train == 'Fatal').astype('int').cm_highestinjury\n",
    "y_test = (y_test == 'Fatal').astype('int').cm_highestinjury"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82ac1b",
   "metadata": {},
   "source": [
    "### Establishing the Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e9fc3",
   "metadata": {},
   "source": [
    "When training a classifier model, it is important to establish a baseline accuracy that our model must surpass in order to be considered meaningful. This baseline is defined for classifers as being the accuracy that you would get by simply predicting the most common classification (in this case, 'non-fatal') every single time.\n",
    "\n",
    "The following cell displays the baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1694fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline accuracy is 0.8192307692307692\n"
     ]
    }
   ],
   "source": [
    "# Checking the majority class\n",
    "print(f'The baseline accuracy is {y_test.value_counts(normalize=True)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca63236",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179853b",
   "metadata": {},
   "source": [
    "When selecting a model to train, its important to keep in mind what we need our model to do. While popular models such as Gradient Boosting, Random Forest, and Neural Networks can all boast high predictive power, they do so at the cost  of interpretability. Such models can rarely explain the reasoning behind their decisions accurately, especiallly when given sparse data like our own.\n",
    "\n",
    "However, there is a simpler model whose priorities better alight with our own. Logistic Regression is a simple classifier model that employs the principles of linear regression to apply a single numeric weight to each word in our dataset that it uses to predict the odds of an accident being fatal when that word is present. This model allows us to see, in quantifiable terms, the affect that a word has on our model's decision to classify an accident as fatal or not. And when given binary target data in particular, Logistic Regression can communicate which classification a particular word is associated with through the sign of its numeric weight.\n",
    "\n",
    "For this project, where we aim to determine the factors that affect accident severity by examining a trained model, interpretability is thee most important consideration. As such, we will be using Logistic Regression in our modelling process.\n",
    "\n",
    "The following cell trains several Logistic Regression models and selects the one with the best performance for use in future inferrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f0b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9917367146317139\n",
      "Testing accuracy: 0.9484330484330484\n"
     ]
    }
   ],
   "source": [
    "# Defining logistic regression parameters to sweep over\n",
    "logreg_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':[0.01,0.1,1,10,100]\n",
    "}\n",
    "# GridSearching logistic regression classifiers\n",
    "logreg_grid = GridSearchCV(LogisticRegression(solver='liblinear'), logreg_params, n_jobs=-1)\n",
    "logreg_grid.fit(X_train_sparse, y_train)\n",
    "# Printing out train and test accuracy scores\n",
    "print(f'Training accuracy: {logreg_grid.score(X_train_sparse, y_train)}')\n",
    "print(f'Testing accuracy: {logreg_grid.score(X_test_sparse, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e1164",
   "metadata": {},
   "source": [
    "Looking at the above testing accuracy of approximately 0.95, we can see that our model has outperformed the baseline accuracy of 0.81 and thus has meaningfully learned to predict severity from our data.\n",
    "\n",
    "Given this, we can now look at the features within the model that have the highest weight in order to make inferrences about factors that most contribute to fatal accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e790cc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>13.295267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witness</th>\n",
       "      <td>12.087108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatally</th>\n",
       "      <td>10.945271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wreckage</th>\n",
       "      <td>10.257947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likely</th>\n",
       "      <td>9.327795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>7.404621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consistent</th>\n",
       "      <td>6.941478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airframe</th>\n",
       "      <td>6.845285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatal</th>\n",
       "      <td>6.666822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radar</th>\n",
       "      <td>6.287115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detected</th>\n",
       "      <td>5.742716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>5.542873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autopsy</th>\n",
       "      <td>5.502295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical</th>\n",
       "      <td>5.413905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spin</th>\n",
       "      <td>5.344792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicology</th>\n",
       "      <td>5.329024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence</th>\n",
       "      <td>5.249952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncontrolled</th>\n",
       "      <td>5.123633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postcrash</th>\n",
       "      <td>5.108166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accident</th>\n",
       "      <td>4.961748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicological</th>\n",
       "      <td>4.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>4.795678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angle</th>\n",
       "      <td>4.745842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scar</th>\n",
       "      <td>4.673965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adequately</th>\n",
       "      <td>4.670409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investigation</th>\n",
       "      <td>4.506360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make_Royse</th>\n",
       "      <td>4.468569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make_Saloff</th>\n",
       "      <td>4.463565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make_Dix</th>\n",
       "      <td>4.455917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>4.399931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Weight\n",
       "witnesses      13.295267\n",
       "witness        12.087108\n",
       "fatally        10.945271\n",
       "wreckage       10.257947\n",
       "likely          9.327795\n",
       "would           7.404621\n",
       "consistent      6.941478\n",
       "airframe        6.845285\n",
       "fatal           6.666822\n",
       "radar           6.287115\n",
       "detected        5.742716\n",
       "impact          5.542873\n",
       "autopsy         5.502295\n",
       "medical         5.413905\n",
       "spin            5.344792\n",
       "toxicology      5.329024\n",
       "evidence        5.249952\n",
       "uncontrolled    5.123633\n",
       "postcrash       5.108166\n",
       "accident        4.961748\n",
       "toxicological   4.833000\n",
       "two             4.795678\n",
       "angle           4.745842\n",
       "scar            4.673965\n",
       "adequately      4.670409\n",
       "investigation   4.506360\n",
       "make_Royse      4.468569\n",
       "make_Saloff     4.463565\n",
       "make_Dix        4.455917\n",
       "site            4.399931"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the model paraemetrs that most determine if an accident is predicted to be fatal\n",
    "parameter_weight_df = pd.DataFrame(logreg_grid.best_estimator_.coef_[0], index = X_train_tfidf.columns)\n",
    "parameter_weight_df.columns = ['Weight']\n",
    "parameter_weight_df.sort_values('Weight', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733fe0c",
   "metadata": {},
   "source": [
    "Looking at the above parameters, we can see three major things that can guide further improvements in our model.\n",
    "\n",
    "Firstly and most importantly, our model _did_ successfully identify words such as airframe that provide insight into flight safety. Looking into the reports that mention the word 'airframe' shows that accidents that involved airframe damage worthy of reporting were much more likley to be fatal.\n",
    "\n",
    "However, these words are being obsured by the presence of self-referrential terms such as 'fatally' and 'wreckage' which directly state that an accident was fatal and by procedural terms such as 'witness' and 'detected' that appear more often in fatal accident reports but hold no insight in and of themselves. We could improve our model's inferrential abilities by removing these terms from our data to force the model to learn more insightful ways of determining which accidents were fatal.\n",
    "\n",
    "And equally importantly, we can see that the make of smaller private planes are considered to be important predictors by our model. This, along with our EDA, highlights the fact that our dataset's overrepresentation of private planes is likely having a substantial effect on our model's predictions. Since the project's overall goal is to provide recommendations for what parts of _commercial_ air travel should be regulated or researched, we would likely get more relevant results by excluding private planes from our model's training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7dcc6",
   "metadata": {},
   "source": [
    "## Continued Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c9784",
   "metadata": {},
   "source": [
    "Since both our model and our data could be further altered to achieve more meaningful results, it would be predunt to refrain from drawing any inferences jut yet and instead focus on implementing these improvements in our next notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
